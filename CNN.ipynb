{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amina04/CNN-lstm/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czEUiywRfcSx"
      },
      "source": [
        "**chargement des fichiers qui sont sur drive**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DFZ7bj9lvkL",
        "outputId": "b56d5e78-64cd-4bbb-9cb8-90a225ba686c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51dfIJmkDCTE"
      },
      "source": [
        "la bibliothéque pandas nous donne le droit de travailler avec la format csv.\n",
        "On utilise panda pour ouvrir la dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_KbZ19tFmx9C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJEfaBQuAH7D"
      },
      "source": [
        "**Donner les noms des column au dataset et spécifier la liste des  string contenu **\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wuEOkN3jXm6l"
      },
      "outputs": [],
      "source": [
        "\n",
        "featureV=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\n",
        "          \"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
        "          \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
        "          \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \n",
        "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
        "          \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"]\n",
        "\n",
        "flagV=['OTH','RSTOS0','SF','SH','RSTO','S2','S1','REJ','S3','RSTR','S0']\n",
        "\n",
        "protocol_typeV=['tcp','udp','icmp']\n",
        "\n",
        "serviceV=['http','smtp','finger','domain_u','auth','telnet','ftp','eco_i','ntp_u','ecr_i','other','private','pop_3','ftp_data',\n",
        "                  'rje','time','mtp','link','remote_job','gopher','ssh','name','whois','domain','login','imap4','daytime','ctf','nntp',\n",
        "                  'shell','IRC','nnsp','http_443','exec','printer','efs','courier','uucp','klogin','kshell','echo','discard','systat',\n",
        "                  'supdup','iso_tsap','hostnames','csnet_ns','pop_2','sunrpc','uucp_path','netbios_ns','netbios_ssn','netbios_dgm',\n",
        "                  'sql_net','vmnet','bgp','Z39_50','ldap','netstat','urh_i','X11','urp_i','pm_dump','tftp_u','tim_i','red_i','icmp',\n",
        "                  'http_2784','harvest','aol','http_8001']\n",
        "\n",
        "binary_attack=['normal','ipsweep', 'nmap', 'portsweep','satan', 'saint', 'mscan','back', 'land', 'neptune', 'pod', 'smurf',\n",
        "               'teardrop', 'apache2', 'udpstorm', 'processtable','mailbomb','buffer_overflow', 'loadmodule', 'perl', 'rootkit',\n",
        "               'xterm', 'ps', 'sqlattack','ftp_write', 'guess_passwd', 'imap', 'multihop','phf', 'spy', 'warezclient',\n",
        "               'warezmaster','snmpgetattack','named', 'xlock', 'xsnoop','sendmail', 'httptunnel', 'worm', 'snmpguess']\n",
        "\n",
        "multiclass_attack={ 'normal': 'normal',\n",
        "        'probe': ['ipsweep.', 'nmap.', 'portsweep.','satan.', 'saint.', 'mscan.'],\n",
        "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.','teardrop.', 'apache2.', 'udpstorm.', 'processtable.','mailbomb.'],\n",
        "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.','xterm.', 'ps.', 'sqlattack.'],\n",
        "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.','phf.', 'spy.', 'warezclient.', 'warezmaster.','snmpgetattack.',\n",
        "                   'named.', 'xlock.', 'xsnoop.','sendmail.', 'httptunnel.', 'worm.', 'snmpguess.']}    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH6A-JQMis6W"
      },
      "source": [
        "## **1.Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U68Zsb-vmzNP"
      },
      "outputs": [],
      "source": [
        "data_train=pd.read_csv('/content/drive/MyDrive/data/nsl-kdd/KDDTrain+.txt',names=featureV)\n",
        "data_valid=pd.read_csv('/content/drive/MyDrive/data/nsl-kdd/KDDTest+.txt',names=featureV)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzYkWa64g8D_"
      },
      "source": [
        "data.shape nous donne une vue sur la quantite de data pour train et pour valid(test) et aussi 43 présente le nombre des colonnes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnwDFzAbtkTD",
        "outputId": "804d8b1c-3dc1-45bd-904a-83e9873ff302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125973, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nrknPMq_-kw",
        "outputId": "fad74112-cdc9-47f1-9b48-30c75b53b3b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22544, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data_valid.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyRME3bRjUUS"
      },
      "source": [
        "## **2.pre-process the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHzZCdsbjAs8"
      },
      "source": [
        "\n",
        "ici on supprimes quelque ligne quand le column service contien ces mots pour avoir la meme taille de data tain et data test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DbGEztuI-daq"
      },
      "outputs": [],
      "source": [
        "data_train = data_train.query(\"service != 'aol'\")\n",
        "data_train = data_train.query(\"service != 'harvest'\")\n",
        "data_train = data_train.query(\"service != 'http_2784'\")\n",
        "data_train = data_train.query(\"service != 'http_8001'\")\n",
        "data_train = data_train.query(\"service != 'red_i'\")\n",
        "data_train = data_train.query(\"service != 'urh_i'\")\n",
        "data_train = data_train.query(\"service != 'printer'\")\n",
        "data_train = data_train.query(\"service != 'rje'\")\n",
        "#-------------------------------------------------------------------------------->>>>\n",
        "data_valid = data_valid.query(\"service != 'printer'\")\n",
        "data_valid = data_valid.query(\"service != 'rje'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtQUWgsy1hlo"
      },
      "source": [
        "## **Working with Validation data -Numericalization-**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GbYewACV11N0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#data=données cls=classe binary or multiclass   df=train or test string\n",
        "def preprocessing(data,cls,df): \n",
        "  #----------attack categorization----------------->\n",
        "  data['label']=data['label'].replace(['normal.','normal'],0)\n",
        "  #----------------------binary classification--------------------->\n",
        "  if cls=='binary':\n",
        "    for i in range(len(binary_attack)):\n",
        "      data['label'] = data['label'].replace(binary_attack[i], 1)\n",
        "  #-------------------------splitting features and labels---------------->\n",
        "  y=data['label']\n",
        "  #partier de dataset qui contien les strings\n",
        "  x=data.loc[:,'duration':'hot']\n",
        "  #-----------------converting to binary feature vectors-------------------------------------->  \n",
        "  #on va copier column dans un variable \n",
        "  \n",
        "  t=x.protocol_type.copy()\n",
        "  #puis utiliser la fonction dumies qui transfer en binaire\n",
        "  t=pd.get_dummies(t)\n",
        "  #on va supprimer column l original qui contient string 1 ie tout rows de protocole type \n",
        "  x=x.drop(columns='protocol_type',axis=1)\n",
        "  #ajouter nouveau column qui contient binaire\n",
        "  x=x.join(t)\n",
        "\n",
        "  t1=x.service.copy()\n",
        "  t1=pd.get_dummies(t1)\n",
        "  x=x.drop(columns='service',axis=1)\n",
        "  x=x.join(t1)\n",
        "\n",
        "  t2=x.flag.copy()\n",
        "  t2=pd.get_dummies(t2)\n",
        "  x=x.drop(columns='flag',axis=1)\n",
        "  x=x.join(t2)\n",
        "#mettre tout les valeurs entre 0 et 1  normalization\n",
        "  x = MinMaxScaler(feature_range=(0, 1)).fit_transform(x)\n",
        "  #------------------------------------------------------------------------------>\n",
        "  #-----------------converting to binary label vectors  train--------------------------------------> \n",
        "  yt=y.copy()\n",
        "  yt=pd.get_dummies(yt)\n",
        "#------------------------------------------------------------------------------>\n",
        "  return x,yt\n",
        "  #if df=='train':\n",
        "    #retourner les val et label\n",
        "   # return x,yt\n",
        " # else:\n",
        "  #  return x,yt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O5kbNFLA2wV",
        "outputId": "65bcc815-e880-4ad0-abfc-9ddecddd59f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125793, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#le 1 er var sera pour features et 2em pour label\n",
        "x_valid,y_valid=preprocessing(data_valid,cls='binary',df='valid')\n",
        "x_train,y_train=preprocessing(data_train,cls='binary',df='train')\n",
        "y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mjMA4bcFkY4",
        "outputId": "669388e8-b49e-423c-a169-ebee96aa2c04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125793, 83, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_train.shape\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IooTt8mxzRPN",
        "outputId": "76804ade-e07a-443a-c6ea-d9649d3df15d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22525, 83, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x_valid = np.reshape(x_valid, (x_valid.shape[0], x_valid.shape[1], 1))\n",
        "x_valid.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMVXjwflmQ_Q"
      },
      "source": [
        "## **3.Define the model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wuHn2mqimZdj"
      },
      "outputs": [],
      "source": [
        "#instancier le modéle\n",
        "from tensorflow.keras.models import Sequential\n",
        "model=Sequential()\n",
        "#Créer la couche entrée totalement connecté avec la couche dense\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten, AveragePooling1D,BatchNormalization,SpatialDropout1D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eOb0sH7Y9ZGe"
      },
      "outputs": [],
      "source": [
        "#model.add(Conv1D(32,3, padding=\"same\",activation=\"relu\",input_shape = (x_train.shape[1], 1)))\n",
        "model.add(Conv1D(32,kernel_size =5,padding=\"same\",input_shape = (x_train.shape[1], 1)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "model.add(Dropout(0.05))\n",
        "#2em block\n",
        "model.add(Conv1D(64,kernel_size =5,padding=\"same\"))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "#model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Flatten())\n",
        "#model.add(Dropout(0.5))\n",
        "#(83*32)/4=664\n",
        "model.add(Dense(units=664))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(2, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS7F_PcM0hG_",
        "outputId": "e232b58e-6a37-4d5a-f8cc-34f65ff5303a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 83, 32)            192       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 83, 32)            0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 83, 32)           128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " average_pooling1d (AverageP  (None, 41, 32)           0         \n",
            " ooling1D)                                                       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 41, 32)            0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 41, 64)            10304     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 41, 64)            0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 41, 64)           256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling1d_1 (Averag  (None, 20, 64)           0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20, 64)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 664)               850584    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 664)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1330      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 862,794\n",
            "Trainable params: 862,602\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary() #sert afficher résumé"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy4HLJeR9QSP"
      },
      "source": [
        "**The learning rate** is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. Choosing the learning rate is challenging as a value too small may result in a long training process that could get stuck, whereas a value too large may result in learning a sub-optimal set of weights too fast or an unstable training process.\n",
        "\n",
        "The learning rate may be the most important hyperparameter when configuring your neural network. Therefore it is vital to know how to investigate the effects of the learning rate on model performance and to build an intuition about the dynamics of the learning rate on model behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHmXUL0ajkPU"
      },
      "source": [
        "## **4.Compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PDPu5DFWASEE"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy',keras.metrics.Precision()])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygR7nBG1jw1Q"
      },
      "source": [
        "## **5.Fit the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPZWxB4GjqdP",
        "outputId": "657f7e19-6423-49e0-9bc5-e0aeec145c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 18s 23ms/step - loss: 0.1330 - accuracy: 0.9574 - precision: 0.9574 - val_loss: 0.6792 - val_accuracy: 0.4817 - val_precision: 0.4817\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.1182 - accuracy: 0.9616 - precision: 0.9616 - val_loss: 0.5485 - val_accuracy: 0.7648 - val_precision: 0.7648\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0975 - accuracy: 0.9648 - precision: 0.9648 - val_loss: 0.4990 - val_accuracy: 0.7831 - val_precision: 0.7831\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0886 - accuracy: 0.9677 - precision: 0.9677 - val_loss: 0.6616 - val_accuracy: 0.7968 - val_precision: 0.7968\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0865 - accuracy: 0.9682 - precision: 0.9682 - val_loss: 0.4172 - val_accuracy: 0.8103 - val_precision: 0.8103\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0852 - accuracy: 0.9689 - precision: 0.9689 - val_loss: 0.7999 - val_accuracy: 0.7827 - val_precision: 0.7827\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0841 - accuracy: 0.9691 - precision: 0.9691 - val_loss: 0.6601 - val_accuracy: 0.7976 - val_precision: 0.7976\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0838 - accuracy: 0.9695 - precision: 0.9695 - val_loss: 0.6551 - val_accuracy: 0.7905 - val_precision: 0.7905\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0833 - accuracy: 0.9695 - precision: 0.9695 - val_loss: 0.7739 - val_accuracy: 0.7846 - val_precision: 0.7846\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0834 - accuracy: 0.9694 - precision: 0.9694 - val_loss: 0.5683 - val_accuracy: 0.7985 - val_precision: 0.7985\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0833 - accuracy: 0.9690 - precision: 0.9690 - val_loss: 0.6679 - val_accuracy: 0.7844 - val_precision: 0.7844\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0832 - accuracy: 0.9696 - precision: 0.9696 - val_loss: 0.9119 - val_accuracy: 0.7667 - val_precision: 0.7667\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0825 - accuracy: 0.9698 - precision: 0.9698 - val_loss: 0.4349 - val_accuracy: 0.8116 - val_precision: 0.8116\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0826 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.7815 - val_accuracy: 0.7832 - val_precision: 0.7832\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0824 - accuracy: 0.9696 - precision: 0.9696 - val_loss: 0.7552 - val_accuracy: 0.7839 - val_precision: 0.7839\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0824 - accuracy: 0.9696 - precision: 0.9696 - val_loss: 0.6190 - val_accuracy: 0.7948 - val_precision: 0.7948\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0821 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.7150 - val_accuracy: 0.7839 - val_precision: 0.7839\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0817 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.7800 - val_accuracy: 0.7845 - val_precision: 0.7845\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0819 - accuracy: 0.9696 - precision: 0.9696 - val_loss: 0.6001 - val_accuracy: 0.7894 - val_precision: 0.7894\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0819 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.6288 - val_accuracy: 0.7983 - val_precision: 0.7983\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0819 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.9505 - val_accuracy: 0.7682 - val_precision: 0.7682\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0819 - accuracy: 0.9699 - precision: 0.9699 - val_loss: 0.6749 - val_accuracy: 0.7980 - val_precision: 0.7980\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0816 - accuracy: 0.9698 - precision: 0.9698 - val_loss: 0.5863 - val_accuracy: 0.7995 - val_precision: 0.7995\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0815 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.6080 - val_accuracy: 0.8075 - val_precision: 0.8075\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0811 - accuracy: 0.9701 - precision: 0.9701 - val_loss: 0.7162 - val_accuracy: 0.7984 - val_precision: 0.7984\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0813 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.6898 - val_accuracy: 0.7839 - val_precision: 0.7839\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0811 - accuracy: 0.9700 - precision: 0.9700 - val_loss: 0.8407 - val_accuracy: 0.7835 - val_precision: 0.7835\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 5s 22ms/step - loss: 0.0812 - accuracy: 0.9699 - precision: 0.9699 - val_loss: 0.7643 - val_accuracy: 0.7838 - val_precision: 0.7838\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0815 - accuracy: 0.9697 - precision: 0.9697 - val_loss: 0.9038 - val_accuracy: 0.7838 - val_precision: 0.7838\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0808 - accuracy: 0.9699 - precision: 0.9699 - val_loss: 0.7518 - val_accuracy: 0.7846 - val_precision: 0.7846\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0809 - accuracy: 0.9699 - precision: 0.9699 - val_loss: 0.5422 - val_accuracy: 0.8081 - val_precision: 0.8081\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0809 - accuracy: 0.9701 - precision: 0.9701 - val_loss: 0.7962 - val_accuracy: 0.7839 - val_precision: 0.7839\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0809 - accuracy: 0.9700 - precision: 0.9700 - val_loss: 0.6954 - val_accuracy: 0.7978 - val_precision: 0.7978\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0805 - accuracy: 0.9701 - precision: 0.9701 - val_loss: 0.7501 - val_accuracy: 0.7900 - val_precision: 0.7900\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0807 - accuracy: 0.9701 - precision: 0.9701 - val_loss: 0.4708 - val_accuracy: 0.8083 - val_precision: 0.8083\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0805 - accuracy: 0.9701 - precision: 0.9701 - val_loss: 0.6256 - val_accuracy: 0.7989 - val_precision: 0.7989\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0804 - accuracy: 0.9705 - precision: 0.9705 - val_loss: 0.8025 - val_accuracy: 0.7687 - val_precision: 0.7687\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 0.0806 - accuracy: 0.9701 - precision: 0.9701 - val_loss: 0.7334 - val_accuracy: 0.8064 - val_precision: 0.8064\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0800 - accuracy: 0.9705 - precision: 0.9705 - val_loss: 0.5574 - val_accuracy: 0.8084 - val_precision: 0.8084\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0801 - accuracy: 0.9709 - precision: 0.9709 - val_loss: 0.7612 - val_accuracy: 0.7763 - val_precision: 0.7763\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0798 - accuracy: 0.9709 - precision: 0.9709 - val_loss: 0.5929 - val_accuracy: 0.8167 - val_precision: 0.8167\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0793 - accuracy: 0.9714 - precision: 0.9714 - val_loss: 0.5481 - val_accuracy: 0.8077 - val_precision: 0.8077\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0789 - accuracy: 0.9716 - precision: 0.9716 - val_loss: 0.7837 - val_accuracy: 0.7846 - val_precision: 0.7846\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0792 - accuracy: 0.9716 - precision: 0.9716 - val_loss: 0.5159 - val_accuracy: 0.8164 - val_precision: 0.8164\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0790 - accuracy: 0.9713 - precision: 0.9713 - val_loss: 0.6479 - val_accuracy: 0.8196 - val_precision: 0.8196\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0789 - accuracy: 0.9718 - precision: 0.9718 - val_loss: 0.6343 - val_accuracy: 0.8165 - val_precision: 0.8165\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0784 - accuracy: 0.9720 - precision: 0.9720 - val_loss: 0.6323 - val_accuracy: 0.8209 - val_precision: 0.8209\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0784 - accuracy: 0.9718 - precision: 0.9718 - val_loss: 0.5169 - val_accuracy: 0.8309 - val_precision: 0.8309\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0782 - accuracy: 0.9718 - precision: 0.9718 - val_loss: 0.5379 - val_accuracy: 0.8088 - val_precision: 0.8088\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0779 - accuracy: 0.9720 - precision: 0.9720 - val_loss: 0.6974 - val_accuracy: 0.7845 - val_precision: 0.7845\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0777 - accuracy: 0.9720 - precision: 0.9720 - val_loss: 0.7487 - val_accuracy: 0.7857 - val_precision: 0.7857\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0778 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.6993 - val_accuracy: 0.8062 - val_precision: 0.8062\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0779 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.6864 - val_accuracy: 0.7945 - val_precision: 0.7945\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0778 - accuracy: 0.9719 - precision: 0.9719 - val_loss: 0.8728 - val_accuracy: 0.7544 - val_precision: 0.7544\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0778 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.5882 - val_accuracy: 0.8309 - val_precision: 0.8309\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0779 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.7531 - val_accuracy: 0.7895 - val_precision: 0.7895\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0772 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.6911 - val_accuracy: 0.7889 - val_precision: 0.7889\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0777 - accuracy: 0.9720 - precision: 0.9720 - val_loss: 0.6268 - val_accuracy: 0.8014 - val_precision: 0.8014\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0778 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.4847 - val_accuracy: 0.8433 - val_precision: 0.8433\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0772 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.6875 - val_accuracy: 0.8083 - val_precision: 0.8083\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0775 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.8444 - val_accuracy: 0.7673 - val_precision: 0.7673\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0776 - accuracy: 0.9720 - precision: 0.9720 - val_loss: 0.5650 - val_accuracy: 0.8301 - val_precision: 0.8301\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0774 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.6487 - val_accuracy: 0.8145 - val_precision: 0.8145\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0777 - accuracy: 0.9720 - precision: 0.9720 - val_loss: 0.6122 - val_accuracy: 0.8084 - val_precision: 0.8084\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0774 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.6701 - val_accuracy: 0.7988 - val_precision: 0.7988\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0774 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.8033 - val_accuracy: 0.7626 - val_precision: 0.7626\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0773 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.7206 - val_accuracy: 0.8199 - val_precision: 0.8199\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0776 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.6423 - val_accuracy: 0.8190 - val_precision: 0.8190\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0773 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.5955 - val_accuracy: 0.8312 - val_precision: 0.8312\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0772 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.6774 - val_accuracy: 0.8161 - val_precision: 0.8161\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0771 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.7482 - val_accuracy: 0.7782 - val_precision: 0.7782\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0775 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.5480 - val_accuracy: 0.8314 - val_precision: 0.8314\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0774 - accuracy: 0.9724 - precision: 0.9724 - val_loss: 0.4420 - val_accuracy: 0.8432 - val_precision: 0.8432\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0774 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.6692 - val_accuracy: 0.8305 - val_precision: 0.8305\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0772 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.8168 - val_accuracy: 0.7846 - val_precision: 0.7846\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0771 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.7070 - val_accuracy: 0.8008 - val_precision: 0.8008\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0769 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.5639 - val_accuracy: 0.8313 - val_precision: 0.8313\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0773 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.7080 - val_accuracy: 0.7954 - val_precision: 0.7954\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0769 - accuracy: 0.9724 - precision: 0.9724 - val_loss: 0.6207 - val_accuracy: 0.8298 - val_precision: 0.8298\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0772 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.6351 - val_accuracy: 0.8168 - val_precision: 0.8168\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0772 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.6831 - val_accuracy: 0.8303 - val_precision: 0.8303\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0772 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.5965 - val_accuracy: 0.8305 - val_precision: 0.8305\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 5s 21ms/step - loss: 0.0773 - accuracy: 0.9721 - precision: 0.9721 - val_loss: 0.5912 - val_accuracy: 0.8096 - val_precision: 0.8096\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 5s 20ms/step - loss: 0.0770 - accuracy: 0.9722 - precision: 0.9722 - val_loss: 0.5518 - val_accuracy: 0.8301 - val_precision: 0.8301\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 5s 19ms/step - loss: 0.0770 - accuracy: 0.9723 - precision: 0.9723 - val_loss: 0.6334 - val_accuracy: 0.8162 - val_precision: 0.8162\n",
            "Epoch 86/100\n",
            "175/252 [===================>..........] - ETA: 1s - loss: 0.0771 - accuracy: 0.9724 - precision: 0.9724"
          ]
        }
      ],
      "source": [
        "#model.fit(x_train, y_train, epochs = 100, batch_size =1000)\n",
        "model.fit(x_train, y_train, epochs =100,batch_size =500,validation_data=(x_valid,y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBBgVLarFaiz"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, 'my_first_model.png', show_shapes=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}