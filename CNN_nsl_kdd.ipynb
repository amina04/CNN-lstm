{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amina04/CNN-lstm/blob/main/CNN_nsl_kdd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsLD4iW_IxF-"
      },
      "source": [
        "# **chargement des fichiers qui sont sur drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9ULM1ja71F",
        "outputId": "4984024e-ceba-4173-efba-b5e9ac7a8a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSCHbXSsI6bT"
      },
      "source": [
        "la bibliothéque pandas nous donne le droit de travailler avec la format csv.\n",
        "On utilise panda pour ouvrir la dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mn1if4XZbCvI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gRI5Z659cA6l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJM2luLgJBHA"
      },
      "source": [
        "**Donner les noms des column au dataset et spécifier la liste des  string contenu **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I1Id0BvzcO_A"
      },
      "outputs": [],
      "source": [
        "\n",
        "featureV=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\n",
        "          \"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
        "          \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
        "          \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \n",
        "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
        "          \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"]\n",
        "\n",
        "flagV=['OTH','RSTOS0','SF','SH','RSTO','S2','S1','REJ','S3','RSTR','S0']\n",
        "\n",
        "protocol_typeV=['tcp','udp','icmp']\n",
        "\n",
        "serviceV=['http','smtp','finger','domain_u','auth','telnet','ftp','eco_i','ntp_u','ecr_i','other','private','pop_3','ftp_data',\n",
        "                  'rje','time','mtp','link','remote_job','gopher','ssh','name','whois','domain','login','imap4','daytime','ctf','nntp',\n",
        "                  'shell','IRC','nnsp','http_443','exec','printer','efs','courier','uucp','klogin','kshell','echo','discard','systat',\n",
        "                  'supdup','iso_tsap','hostnames','csnet_ns','pop_2','sunrpc','uucp_path','netbios_ns','netbios_ssn','netbios_dgm',\n",
        "                  'sql_net','vmnet','bgp','Z39_50','ldap','netstat','urh_i','X11','urp_i','pm_dump','tftp_u','tim_i','red_i','icmp',\n",
        "                  'http_2784','harvest','aol','http_8001']\n",
        "\n",
        "binary_attack=['normal','ipsweep', 'nmap', 'portsweep','satan', 'saint', 'mscan','back', 'land', 'neptune', 'pod', 'smurf',\n",
        "               'teardrop', 'apache2', 'udpstorm', 'processtable','mailbomb','buffer_overflow', 'loadmodule', 'perl', 'rootkit',\n",
        "               'xterm', 'ps', 'sqlattack','ftp_write', 'guess_passwd', 'imap', 'multihop','phf', 'spy', 'warezclient',\n",
        "               'warezmaster','snmpgetattack','named', 'xlock', 'xsnoop','sendmail', 'httptunnel', 'worm', 'snmpguess']\n",
        "\n",
        "multiclass_attack={ 'normal': 'normal',\n",
        "        'probe': ['ipsweep.', 'nmap.', 'portsweep.','satan.', 'saint.', 'mscan.'],\n",
        "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.','teardrop.', 'apache2.', 'udpstorm.', 'processtable.','mailbomb.'],\n",
        "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.','xterm.', 'ps.', 'sqlattack.'],\n",
        "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.','phf.', 'spy.', 'warezclient.', 'warezmaster.','snmpgetattack.',\n",
        "                   'named.', 'xlock.', 'xsnoop.','sendmail.', 'httptunnel.', 'worm.', 'snmpguess.']}    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fLhfgI3JIjz"
      },
      "source": [
        "## **1.Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2OJYQsm2cTRl"
      },
      "outputs": [],
      "source": [
        "data_train=pd.read_csv('/content/drive/MyDrive/data/nsl-kdd/KDDTrain+.txt',names=featureV)\n",
        "data_test=pd.read_csv('/content/drive/MyDrive/data/nsl-kdd/KDDTest-21.txt',names=featureV)\n",
        "data_valid=pd.read_csv('/content/drive/MyDrive/data/nsl-kdd/KDDTest+.txt',names=featureV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx6dswdEXGN3",
        "outputId": "8f9dbcd8-b092-4df0-a2ea-e40b5269af83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125973, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rNH_mHKEW3-C"
      },
      "outputs": [],
      "source": [
        "# data_train=pd.concat([data_train,data_train_2]).drop_duplicates(keep=False)\n",
        "# data_train.reset_index(drop=True, inplace = True)\n",
        "# data_train.shape\n",
        "data_train=pd.concat([data_train,data__test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuPxkOzXE-87",
        "outputId": "3641ff80-afc2-4db7-ebfb-3d3881e157bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numbers of protocol_type: 3\n",
            "number of 'service' in train datasets: 70\n",
            "number of 'flag' in train datasets: 11\n"
          ]
        }
      ],
      "source": [
        "print(f\"numbers of protocol_type: {len(data_train['protocol_type'].value_counts())}\")\n",
        "print(f\"number of 'service' in train datasets: {len(data_train.service.value_counts())}\")\n",
        "print(f\"number of 'flag' in train datasets: {len(data_train['flag'].value_counts())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **cleaning the data**"
      ],
      "metadata": {
        "id": "NmaLSdk3RjUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if there are any NULL values in the dataset.\n",
        "\n",
        "data_train.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbW2xJp0Rh-L",
        "outputId": "93d0088c-8497-4e6d-bb95-b87d391fec7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMjFKWglFZ69",
        "outputId": "210291ec-cab8-4935-cb8e-7d66f160317d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['normal', 'neptune', 'warezclient', 'ipsweep', 'portsweep',\n",
              "       'teardrop', 'nmap', 'satan', 'smurf', 'pod', 'back',\n",
              "       'guess_passwd', 'ftp_write', 'multihop', 'rootkit',\n",
              "       'buffer_overflow', 'imap', 'warezmaster', 'phf', 'land',\n",
              "       'loadmodule', 'spy', 'perl', 'snmpguess', 'processtable', 'saint',\n",
              "       'mscan', 'apache2', 'httptunnel', 'mailbomb', 'snmpgetattack',\n",
              "       'worm', 'sendmail', 'xlock', 'xterm', 'xsnoop', 'ps', 'named',\n",
              "       'udpstorm', 'sqlattack'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data_train.label.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX6CfbgCd3rW",
        "outputId": "ef98e641-6ede-4b79-8c8f-8b09193cbe18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137823, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aC0f4xYMdlj",
        "outputId": "b4979434-8bc7-46ba-8d10-a24e31342169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of numeric features: (137823, 38)\n",
            "shape of object features: (137823, 3)\n"
          ]
        }
      ],
      "source": [
        "df_train_obj = data_train.iloc[:, :-2].select_dtypes(include='object')\n",
        "df_train_num = data_train.iloc[:, :-2].select_dtypes(exclude='object')\n",
        "\n",
        "# df_train_2_obj = data_train_2.iloc[:, :-2].select_dtypes(include='object')\n",
        "# df_train_2_num = data_train_2.iloc[:, :-2].select_dtypes(exclude='object')\n",
        "\n",
        "print(f\"shape of numeric features: {df_train_num.shape}\")\n",
        "print(f\"shape of object features: {df_train_obj.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB-5FVuz0gZR",
        "outputId": "d43f45c0-a1ee-4421-8057-3a356c6fc9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of numeric features: (22544, 38)\n",
            "shape of object features: (22544, 3)\n"
          ]
        }
      ],
      "source": [
        "df_valid_obj = data_valid.iloc[:, :-2].select_dtypes(include='object')\n",
        "df_valid_num = data_valid.iloc[:, :-2].select_dtypes(exclude='object')\n",
        "\n",
        "print(f\"shape of numeric features: {df_valid_num.shape}\")\n",
        "print(f\"shape of object features: {df_valid_obj.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XjvjEy440ycV",
        "outputId": "c087b4aa-d3ac-4f03-fb22-d3b1c13238d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  protocol_type   service flag\n",
              "0           tcp  ftp_data   SF\n",
              "1           udp     other   SF\n",
              "2           tcp   private   S0\n",
              "3           tcp      http   SF\n",
              "4           tcp      http   SF"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed71fdd9-7d12-46c8-926b-4ab876b061b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed71fdd9-7d12-46c8-926b-4ab876b061b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed71fdd9-7d12-46c8-926b-4ab876b061b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed71fdd9-7d12-46c8-926b-4ab876b061b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_train_obj.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8FSai9sw-UH"
      },
      "source": [
        "encoder les labels 0 pour normal et 1 attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6humYfTHYUxo"
      },
      "outputs": [],
      "source": [
        "data_train['label']=data_train['label'].replace(['normal.','normal'],0)\n",
        "for i in range(len(binary_attack)):\n",
        "  data_train['label'] = data_train['label'].replace(binary_attack[i], 1)\n",
        "y_train=data_train['label']\n",
        "\n",
        "# data_train_2['label']=data_train_2['label'].replace(['normal.','normal'],0)\n",
        "# for i in range(len(binary_attack)):\n",
        "#   data_train_2['label'] = data_train_2['label'].replace(binary_attack[i], 1)\n",
        "# y_train_2=data_train_2['label']\n",
        "\n",
        "\n",
        "data_valid['label']=data_valid['label'].replace(['normal.','normal'],0)\n",
        "for i in range(len(binary_attack)):\n",
        "  data_valid['label'] = data_valid['label'].replace(binary_attack[i], 1)\n",
        "y_valid=data_valid['label']\n",
        "#supprimer la colonne la bel de dataset car on a créer une copier déja ===>séparation\n",
        "del data_train['label']\n",
        "del data_valid['label']\n",
        "# del data_train_2['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h8quUzdZAcq",
        "outputId": "323b0a3d-7a2a-45a8-9e33-8de6ee8a51ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137823, 42)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtY3TbJRxj3j"
      },
      "source": [
        "## **2.Working with Validation data -Numericalization-**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "nNsow4c72YjB",
        "outputId": "9865dec5-d806-4f10-fd9a-ed600207cd33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_enc shape: (137823, 122)\n",
            "X_test_enc shape: (22544, 122)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1\n",
              "0  1  0\n",
              "1  1  0\n",
              "2  0  1\n",
              "3  1  0\n",
              "4  1  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a933f060-78e6-45d6-961f-ebd38852c025\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a933f060-78e6-45d6-961f-ebd38852c025')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a933f060-78e6-45d6-961f-ebd38852c025 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a933f060-78e6-45d6-961f-ebd38852c025');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import numpy as np \n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "#encoder juste les les column qui contient string\n",
        "data_train_enc = enc.fit_transform(df_train_obj).toarray()\n",
        "train_enc_features = enc.get_feature_names_out(input_features=df_train_obj.columns)\n",
        "data_valid_enc = enc.transform(df_valid_obj).toarray()\n",
        "test_enc_features = enc.get_feature_names_out(input_features=df_valid_obj.columns)\n",
        "\n",
        "# data_train_2_enc = enc.fit_transform(df_train_2_obj).toarray()\n",
        "# train_2_enc_features = enc.get_feature_names_out(input_features=df_train_2_obj.columns)\n",
        "#concatiner string avec num columns\n",
        "X_train_enc = np.c_[df_train_num, data_train_enc]\n",
        "X_valid_enc = np.c_[df_valid_num, data_valid_enc]\n",
        "# X_train_2_enc = np.c_[df_train_2_num, data_train_2_enc]\n",
        "print(f\"X_train_enc shape: {X_train_enc.shape}\")\n",
        "print(f\"X_test_enc shape: {X_valid_enc.shape}\")\n",
        "# print(f\"X_train_enc shape: {X_train_2_enc.shape}\")\n",
        "######################################\n",
        "#encoder les labels\n",
        "y_train=pd.get_dummies(y_train)\n",
        "y_valid=pd.get_dummies(y_valid)\n",
        "# y_train_2=pd.get_dummies(y_train_2)\n",
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKdo5jM13Vg-",
        "outputId": "d9f61a77-8f9c-4473-ccd3-8a1e97c0bfe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaler = scaler.fit_transform(X_train_enc)\n",
        "X_valid_scaler = scaler.fit_transform(X_valid_enc)\n",
        "# X_train_2_scaler = scaler.fit_transform(X_train_2_enc)\n",
        "########################\n",
        "y_train=scaler.fit_transform(y_train)\n",
        "y_valid=scaler.fit_transform(y_valid)\n",
        "# y_train_2=scaler.fit_transform(y_train_2)\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YuBYC7l35eAP"
      },
      "outputs": [],
      "source": [
        "x_train = np.reshape(X_train_scaler, (X_train_scaler.shape[0], X_train_scaler.shape[1], 1))\n",
        "# x_train_2 = np.reshape(X_train_2_scaler, (X_train_2_scaler.shape[0], X_train_2_scaler.shape[1], 1))\n",
        "#x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# The next step is to split training and testing data. For this we will use sklearn function train_test_split().\n",
        "\n",
        "x_train, x_test ,y_train, y_test = train_test_split(x_train, y_train, test_size=10000)\n",
        "x_train.shape, x_test.shape ,y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9GobiPvjVgf",
        "outputId": "3d306de1-79a8-4d51-a0c2-787ed3097ba0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((127823, 122, 1), (10000, 122, 1), (127823, 2), (10000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd66AC83-xWU",
        "outputId": "3ce9dd49-5366-4540-9220-889068a3d7a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22544, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyuEsLL352BU",
        "outputId": "f414d5ca-98e3-4663-815a-2d02193edc86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22544, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x_valid = np.reshape(X_valid_scaler, (X_valid_scaler.shape[0],X_valid_scaler.shape[1], 1))\n",
        "\n",
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJx8SgMNxx1H"
      },
      "source": [
        "## **3.Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eU5qurPR6Juw"
      },
      "outputs": [],
      "source": [
        "#instancier le modéle\n",
        "from tensorflow.keras.models import Sequential\n",
        "model=Sequential()\n",
        "#Créer la couche entrée totalement connecté avec la couche dense\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten, AveragePooling1D,BatchNormalization,SpatialDropout1D,MaxPool1D\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p22rb7YTTgRt"
      },
      "source": [
        "**Spatial 1D version of Dropout.**\n",
        "\n",
        "This version performs the same function as Dropout, however, it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhE1omyQ6ZYf",
        "outputId": "e502533e-95c5-48b6-8b78-61224412b185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 122, 32)           192       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 122, 32)           0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 122, 32)          128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " average_pooling1d (AverageP  (None, 61, 32)           0         \n",
            " ooling1D)                                                       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 61, 64)            10304     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 61, 64)            0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 61, 64)           256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling1d_1 (Averag  (None, 30, 64)           0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 30, 64)           0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 30, 128)           41088     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 30, 128)           0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 30, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling1d_2 (Averag  (None, 15, 128)          0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 15, 256)           164096    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 15, 256)           0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 256)          1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " average_pooling1d_3 (Averag  (None, 7, 256)           0         \n",
            " ePooling1D)                                                     \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 7, 256)           0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                53790     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,452\n",
            "Trainable params: 270,492\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.add(Conv1D(32,kernel_size =5,padding=\"same\",input_shape =(x_train.shape[1],1)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "#model.add(SpatialDropout1D(0.05))\n",
        "#model.add(Dropout(0.1))\n",
        "# #2em block\n",
        "model.add(Conv1D(64,kernel_size =5,padding=\"same\",))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "#model.add(Dropout(0.1))\n",
        "#3em block\n",
        "model.add(Conv1D(128,kernel_size =5,padding=\"same\",))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "#model.add(SpatialDropout1D(0.1))\n",
        "#model.add(Dropout(0.1))\n",
        "#4em block\n",
        "model.add(Conv1D(256,kernel_size =5,padding=\"same\",))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling1D(pool_size=2))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "#model.add(Dropout(0.1))\n",
        "#5em block\n",
        "# model.add(Conv1D(512,kernel_size =5,padding=\"same\",))\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(AveragePooling1D(pool_size=2))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=30, activation=\"relu\"))\n",
        "\n",
        "#model.add(Dropout(0.3))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))\n",
        "model.summary() #sert afficher résumés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcSoYc_Ex-DA"
      },
      "source": [
        "## **4.Compile the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "n-xUy2qL9DSe"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy',keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "797225XmyG-H"
      },
      "source": [
        "## **5.Fit the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWSnQYZO32uX"
      },
      "source": [
        "**The loss function** is perhaps the most important\n",
        "aspect of neural networks. The gradients are calculated\n",
        "using the loss function, and the gradient is used to update\n",
        "the neural network biases, increasing or decreasing the\n",
        "neural network weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og6feE_69Gus",
        "outputId": "3dad1a43-369b-4c47-b264-d892b556035c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "256/256 [==============================] - 23s 53ms/step - loss: 0.1615 - accuracy: 0.9398 - precision: 0.9375 - val_loss: 0.5773 - val_accuracy: 0.5701 - val_precision: 0.6435\n",
            "Epoch 2/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0958 - accuracy: 0.9646 - precision: 0.9646 - val_loss: 0.2315 - val_accuracy: 0.9237 - val_precision: 0.9178\n",
            "Epoch 3/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0790 - accuracy: 0.9697 - precision: 0.9696 - val_loss: 0.1665 - val_accuracy: 0.9237 - val_precision: 0.9247\n",
            "Epoch 4/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0693 - accuracy: 0.9737 - precision: 0.9735 - val_loss: 0.1367 - val_accuracy: 0.9391 - val_precision: 0.9402\n",
            "Epoch 5/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0629 - accuracy: 0.9764 - precision: 0.9764 - val_loss: 0.1551 - val_accuracy: 0.9332 - val_precision: 0.9348\n",
            "Epoch 6/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0586 - accuracy: 0.9784 - precision: 0.9782 - val_loss: 0.1199 - val_accuracy: 0.9552 - val_precision: 0.9558\n",
            "Epoch 7/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0552 - accuracy: 0.9796 - precision: 0.9795 - val_loss: 0.1194 - val_accuracy: 0.9557 - val_precision: 0.9561\n",
            "Epoch 8/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0528 - accuracy: 0.9801 - precision: 0.9801 - val_loss: 0.1082 - val_accuracy: 0.9579 - val_precision: 0.9592\n",
            "Epoch 9/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0493 - accuracy: 0.9817 - precision: 0.9818 - val_loss: 0.1172 - val_accuracy: 0.9574 - val_precision: 0.9578\n",
            "Epoch 10/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0479 - accuracy: 0.9821 - precision: 0.9819 - val_loss: 0.1118 - val_accuracy: 0.9569 - val_precision: 0.9575\n",
            "Epoch 11/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0458 - accuracy: 0.9829 - precision: 0.9829 - val_loss: 0.1000 - val_accuracy: 0.9619 - val_precision: 0.9630\n",
            "Epoch 12/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0440 - accuracy: 0.9834 - precision: 0.9833 - val_loss: 0.0936 - val_accuracy: 0.9616 - val_precision: 0.9625\n",
            "Epoch 13/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0412 - accuracy: 0.9846 - precision: 0.9846 - val_loss: 0.1008 - val_accuracy: 0.9617 - val_precision: 0.9638\n",
            "Epoch 14/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0401 - accuracy: 0.9852 - precision: 0.9851 - val_loss: 0.0943 - val_accuracy: 0.9631 - val_precision: 0.9638\n",
            "Epoch 15/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0381 - accuracy: 0.9858 - precision: 0.9857 - val_loss: 0.0836 - val_accuracy: 0.9652 - val_precision: 0.9653\n",
            "Epoch 16/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0371 - accuracy: 0.9862 - precision: 0.9860 - val_loss: 0.0856 - val_accuracy: 0.9641 - val_precision: 0.9646\n",
            "Epoch 17/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0359 - accuracy: 0.9865 - precision: 0.9864 - val_loss: 0.0795 - val_accuracy: 0.9671 - val_precision: 0.9676\n",
            "Epoch 18/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0337 - accuracy: 0.9872 - precision: 0.9873 - val_loss: 0.0982 - val_accuracy: 0.9545 - val_precision: 0.9516\n",
            "Epoch 19/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0338 - accuracy: 0.9873 - precision: 0.9873 - val_loss: 0.0798 - val_accuracy: 0.9666 - val_precision: 0.9668\n",
            "Epoch 20/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0321 - accuracy: 0.9883 - precision: 0.9882 - val_loss: 0.0732 - val_accuracy: 0.9683 - val_precision: 0.9683\n",
            "Epoch 21/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0315 - accuracy: 0.9880 - precision: 0.9880 - val_loss: 0.0793 - val_accuracy: 0.9689 - val_precision: 0.9692\n",
            "Epoch 22/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0304 - accuracy: 0.9884 - precision: 0.9883 - val_loss: 0.0720 - val_accuracy: 0.9701 - val_precision: 0.9700\n",
            "Epoch 23/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0298 - accuracy: 0.9887 - precision: 0.9887 - val_loss: 0.0854 - val_accuracy: 0.9570 - val_precision: 0.9568\n",
            "Epoch 24/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0297 - accuracy: 0.9887 - precision: 0.9885 - val_loss: 0.0983 - val_accuracy: 0.9552 - val_precision: 0.9554\n",
            "Epoch 25/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0291 - accuracy: 0.9891 - precision: 0.9889 - val_loss: 0.0686 - val_accuracy: 0.9710 - val_precision: 0.9711\n",
            "Epoch 26/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0280 - accuracy: 0.9893 - precision: 0.9893 - val_loss: 0.0703 - val_accuracy: 0.9711 - val_precision: 0.9707\n",
            "Epoch 27/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0280 - accuracy: 0.9895 - precision: 0.9894 - val_loss: 0.0939 - val_accuracy: 0.9570 - val_precision: 0.9570\n",
            "Epoch 28/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0275 - accuracy: 0.9893 - precision: 0.9895 - val_loss: 0.0705 - val_accuracy: 0.9696 - val_precision: 0.9716\n",
            "Epoch 29/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0266 - accuracy: 0.9900 - precision: 0.9900 - val_loss: 0.0778 - val_accuracy: 0.9684 - val_precision: 0.9676\n",
            "Epoch 30/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0267 - accuracy: 0.9897 - precision: 0.9897 - val_loss: 0.0724 - val_accuracy: 0.9700 - val_precision: 0.9702\n",
            "Epoch 31/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0261 - accuracy: 0.9898 - precision: 0.9900 - val_loss: 0.0621 - val_accuracy: 0.9729 - val_precision: 0.9736\n",
            "Epoch 32/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0254 - accuracy: 0.9899 - precision: 0.9901 - val_loss: 0.0686 - val_accuracy: 0.9656 - val_precision: 0.9653\n",
            "Epoch 33/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0248 - accuracy: 0.9904 - precision: 0.9906 - val_loss: 0.0649 - val_accuracy: 0.9717 - val_precision: 0.9716\n",
            "Epoch 34/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0251 - accuracy: 0.9903 - precision: 0.9903 - val_loss: 0.0736 - val_accuracy: 0.9670 - val_precision: 0.9672\n",
            "Epoch 35/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0246 - accuracy: 0.9905 - precision: 0.9905 - val_loss: 0.0677 - val_accuracy: 0.9683 - val_precision: 0.9703\n",
            "Epoch 36/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0245 - accuracy: 0.9905 - precision: 0.9905 - val_loss: 0.0589 - val_accuracy: 0.9751 - val_precision: 0.9752\n",
            "Epoch 37/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0245 - accuracy: 0.9905 - precision: 0.9905 - val_loss: 0.0596 - val_accuracy: 0.9735 - val_precision: 0.9735\n",
            "Epoch 38/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0234 - accuracy: 0.9910 - precision: 0.9909 - val_loss: 0.0580 - val_accuracy: 0.9743 - val_precision: 0.9738\n",
            "Epoch 39/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0234 - accuracy: 0.9908 - precision: 0.9908 - val_loss: 0.0565 - val_accuracy: 0.9753 - val_precision: 0.9752\n",
            "Epoch 40/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0236 - accuracy: 0.9908 - precision: 0.9907 - val_loss: 0.0678 - val_accuracy: 0.9716 - val_precision: 0.9707\n",
            "Epoch 41/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0231 - accuracy: 0.9912 - precision: 0.9912 - val_loss: 0.0586 - val_accuracy: 0.9743 - val_precision: 0.9733\n",
            "Epoch 42/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0227 - accuracy: 0.9912 - precision: 0.9910 - val_loss: 0.0539 - val_accuracy: 0.9766 - val_precision: 0.9762\n",
            "Epoch 43/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0224 - accuracy: 0.9914 - precision: 0.9914 - val_loss: 0.0531 - val_accuracy: 0.9769 - val_precision: 0.9762\n",
            "Epoch 44/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0219 - accuracy: 0.9912 - precision: 0.9911 - val_loss: 0.0593 - val_accuracy: 0.9738 - val_precision: 0.9738\n",
            "Epoch 45/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0219 - accuracy: 0.9915 - precision: 0.9915 - val_loss: 0.0551 - val_accuracy: 0.9750 - val_precision: 0.9755\n",
            "Epoch 46/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0214 - accuracy: 0.9915 - precision: 0.9913 - val_loss: 0.0653 - val_accuracy: 0.9739 - val_precision: 0.9739\n",
            "Epoch 47/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0216 - accuracy: 0.9916 - precision: 0.9914 - val_loss: 0.0576 - val_accuracy: 0.9759 - val_precision: 0.9762\n",
            "Epoch 48/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0221 - accuracy: 0.9914 - precision: 0.9914 - val_loss: 0.0655 - val_accuracy: 0.9722 - val_precision: 0.9725\n",
            "Epoch 49/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0216 - accuracy: 0.9917 - precision: 0.9916 - val_loss: 0.0535 - val_accuracy: 0.9778 - val_precision: 0.9776\n",
            "Epoch 50/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0216 - accuracy: 0.9915 - precision: 0.9914 - val_loss: 0.0663 - val_accuracy: 0.9772 - val_precision: 0.9757\n",
            "Epoch 51/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0209 - accuracy: 0.9918 - precision: 0.9917 - val_loss: 0.0605 - val_accuracy: 0.9745 - val_precision: 0.9744\n",
            "Epoch 52/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0212 - accuracy: 0.9917 - precision: 0.9916 - val_loss: 0.0556 - val_accuracy: 0.9778 - val_precision: 0.9781\n",
            "Epoch 53/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0210 - accuracy: 0.9918 - precision: 0.9918 - val_loss: 0.0533 - val_accuracy: 0.9764 - val_precision: 0.9754\n",
            "Epoch 54/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0205 - accuracy: 0.9917 - precision: 0.9916 - val_loss: 0.0633 - val_accuracy: 0.9687 - val_precision: 0.9694\n",
            "Epoch 55/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0208 - accuracy: 0.9919 - precision: 0.9917 - val_loss: 0.0619 - val_accuracy: 0.9774 - val_precision: 0.9769\n",
            "Epoch 56/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0207 - accuracy: 0.9919 - precision: 0.9916 - val_loss: 0.0530 - val_accuracy: 0.9756 - val_precision: 0.9756\n",
            "Epoch 57/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0204 - accuracy: 0.9922 - precision: 0.9922 - val_loss: 0.0529 - val_accuracy: 0.9775 - val_precision: 0.9788\n",
            "Epoch 58/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0199 - accuracy: 0.9920 - precision: 0.9919 - val_loss: 0.0493 - val_accuracy: 0.9802 - val_precision: 0.9797\n",
            "Epoch 59/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0194 - accuracy: 0.9925 - precision: 0.9924 - val_loss: 0.0616 - val_accuracy: 0.9752 - val_precision: 0.9751\n",
            "Epoch 60/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0198 - accuracy: 0.9925 - precision: 0.9924 - val_loss: 0.0534 - val_accuracy: 0.9759 - val_precision: 0.9753\n",
            "Epoch 61/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0195 - accuracy: 0.9922 - precision: 0.9922 - val_loss: 0.0512 - val_accuracy: 0.9777 - val_precision: 0.9776\n",
            "Epoch 62/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0193 - accuracy: 0.9924 - precision: 0.9923 - val_loss: 0.0501 - val_accuracy: 0.9789 - val_precision: 0.9784\n",
            "Epoch 63/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0193 - accuracy: 0.9923 - precision: 0.9922 - val_loss: 0.0544 - val_accuracy: 0.9775 - val_precision: 0.9770\n",
            "Epoch 64/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0194 - accuracy: 0.9924 - precision: 0.9923 - val_loss: 0.0530 - val_accuracy: 0.9763 - val_precision: 0.9765\n",
            "Epoch 65/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0195 - accuracy: 0.9923 - precision: 0.9922 - val_loss: 0.0496 - val_accuracy: 0.9798 - val_precision: 0.9798\n",
            "Epoch 66/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0190 - accuracy: 0.9926 - precision: 0.9923 - val_loss: 0.0476 - val_accuracy: 0.9800 - val_precision: 0.9796\n",
            "Epoch 67/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0188 - accuracy: 0.9926 - precision: 0.9924 - val_loss: 0.0541 - val_accuracy: 0.9768 - val_precision: 0.9760\n",
            "Epoch 68/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0188 - accuracy: 0.9925 - precision: 0.9924 - val_loss: 0.0540 - val_accuracy: 0.9768 - val_precision: 0.9768\n",
            "Epoch 69/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0189 - accuracy: 0.9927 - precision: 0.9927 - val_loss: 0.0559 - val_accuracy: 0.9768 - val_precision: 0.9765\n",
            "Epoch 70/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0186 - accuracy: 0.9926 - precision: 0.9925 - val_loss: 0.0521 - val_accuracy: 0.9780 - val_precision: 0.9781\n",
            "Epoch 71/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0185 - accuracy: 0.9927 - precision: 0.9928 - val_loss: 0.0608 - val_accuracy: 0.9708 - val_precision: 0.9708\n",
            "Epoch 72/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0186 - accuracy: 0.9927 - precision: 0.9926 - val_loss: 0.0488 - val_accuracy: 0.9783 - val_precision: 0.9782\n",
            "Epoch 73/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0181 - accuracy: 0.9928 - precision: 0.9929 - val_loss: 0.0477 - val_accuracy: 0.9791 - val_precision: 0.9789\n",
            "Epoch 74/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0182 - accuracy: 0.9927 - precision: 0.9926 - val_loss: 0.0669 - val_accuracy: 0.9688 - val_precision: 0.9684\n",
            "Epoch 75/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0182 - accuracy: 0.9928 - precision: 0.9926 - val_loss: 0.0738 - val_accuracy: 0.9649 - val_precision: 0.9638\n",
            "Epoch 76/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0183 - accuracy: 0.9927 - precision: 0.9927 - val_loss: 0.0518 - val_accuracy: 0.9774 - val_precision: 0.9768\n",
            "Epoch 77/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0178 - accuracy: 0.9931 - precision: 0.9930 - val_loss: 0.0484 - val_accuracy: 0.9807 - val_precision: 0.9808\n",
            "Epoch 78/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0179 - accuracy: 0.9929 - precision: 0.9929 - val_loss: 0.0528 - val_accuracy: 0.9772 - val_precision: 0.9772\n",
            "Epoch 79/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0176 - accuracy: 0.9929 - precision: 0.9929 - val_loss: 0.0618 - val_accuracy: 0.9729 - val_precision: 0.9724\n",
            "Epoch 80/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0180 - accuracy: 0.9931 - precision: 0.9930 - val_loss: 0.0477 - val_accuracy: 0.9800 - val_precision: 0.9805\n",
            "Epoch 81/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0178 - accuracy: 0.9928 - precision: 0.9928 - val_loss: 0.0499 - val_accuracy: 0.9784 - val_precision: 0.9783\n",
            "Epoch 82/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0174 - accuracy: 0.9931 - precision: 0.9930 - val_loss: 0.0467 - val_accuracy: 0.9795 - val_precision: 0.9798\n",
            "Epoch 83/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0174 - accuracy: 0.9933 - precision: 0.9931 - val_loss: 0.0461 - val_accuracy: 0.9808 - val_precision: 0.9813\n",
            "Epoch 84/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0169 - accuracy: 0.9935 - precision: 0.9934 - val_loss: 0.0501 - val_accuracy: 0.9780 - val_precision: 0.9779\n",
            "Epoch 85/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0172 - accuracy: 0.9932 - precision: 0.9931 - val_loss: 0.0485 - val_accuracy: 0.9786 - val_precision: 0.9786\n",
            "Epoch 86/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0170 - accuracy: 0.9931 - precision: 0.9932 - val_loss: 0.0533 - val_accuracy: 0.9764 - val_precision: 0.9761\n",
            "Epoch 87/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0176 - accuracy: 0.9932 - precision: 0.9932 - val_loss: 0.0528 - val_accuracy: 0.9771 - val_precision: 0.9773\n",
            "Epoch 88/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0172 - accuracy: 0.9933 - precision: 0.9932 - val_loss: 0.0492 - val_accuracy: 0.9770 - val_precision: 0.9770\n",
            "Epoch 89/100\n",
            "256/256 [==============================] - 10s 40ms/step - loss: 0.0173 - accuracy: 0.9930 - precision: 0.9930 - val_loss: 0.0489 - val_accuracy: 0.9806 - val_precision: 0.9808\n",
            "Epoch 90/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0170 - accuracy: 0.9932 - precision: 0.9932 - val_loss: 0.0445 - val_accuracy: 0.9815 - val_precision: 0.9811\n",
            "Epoch 91/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0166 - accuracy: 0.9933 - precision: 0.9933 - val_loss: 0.0603 - val_accuracy: 0.9701 - val_precision: 0.9692\n",
            "Epoch 92/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0168 - accuracy: 0.9934 - precision: 0.9933 - val_loss: 0.0486 - val_accuracy: 0.9772 - val_precision: 0.9768\n",
            "Epoch 93/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0165 - accuracy: 0.9935 - precision: 0.9934 - val_loss: 0.0503 - val_accuracy: 0.9760 - val_precision: 0.9755\n",
            "Epoch 94/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0168 - accuracy: 0.9934 - precision: 0.9932 - val_loss: 0.0481 - val_accuracy: 0.9795 - val_precision: 0.9790\n",
            "Epoch 95/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0163 - accuracy: 0.9936 - precision: 0.9935 - val_loss: 0.0467 - val_accuracy: 0.9801 - val_precision: 0.9802\n",
            "Epoch 96/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0164 - accuracy: 0.9935 - precision: 0.9934 - val_loss: 0.0445 - val_accuracy: 0.9809 - val_precision: 0.9808\n",
            "Epoch 97/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0168 - accuracy: 0.9932 - precision: 0.9930 - val_loss: 0.0484 - val_accuracy: 0.9776 - val_precision: 0.9777\n",
            "Epoch 98/100\n",
            "256/256 [==============================] - 10s 41ms/step - loss: 0.0167 - accuracy: 0.9932 - precision: 0.9932 - val_loss: 0.0522 - val_accuracy: 0.9770 - val_precision: 0.9762\n",
            "Epoch 99/100\n",
            "256/256 [==============================] - 11s 42ms/step - loss: 0.0164 - accuracy: 0.9935 - precision: 0.9934 - val_loss: 0.0854 - val_accuracy: 0.9651 - val_precision: 0.9649\n",
            "Epoch 100/100\n",
            "256/256 [==============================] - 11s 41ms/step - loss: 0.0163 - accuracy: 0.9933 - precision: 0.9933 - val_loss: 0.0465 - val_accuracy: 0.9801 - val_precision: 0.9803\n"
          ]
        }
      ],
      "source": [
        "#model.fit(x_train, y_train, epochs = 100, batch_size =1000)\n",
        "#model.fit(x_train, y_train, epochs =80,batch_size =128,validation_data=(x_valid, y_valid),callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1))\n",
        "from keras.callbacks import EarlyStopping\n",
        "#history = model.fit(x_train, y_train, epochs =80,batch_size =128,validation_data=(x_valid, y_valid),callbacks = [EarlyStopping(monitor='val_loss', patience=5)])\n",
        "#history = model.fit(x_train, y_train, epochs =100,batch_size =500)\n",
        "history = model.fit(x_train, y_train, epochs =100,batch_size =500,validation_data=(x_valid, y_valid))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred = model.predict(x_test)\n",
        "y_pred= np.argmax(pred, axis = 1)"
      ],
      "metadata": {
        "id": "PiH2pvD7FfH-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Ti8Cv92xglZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "badb52c1-dd5e-48ab-e6e5-f85658a71b38"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3ddda8ef07c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (100,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "loss_val = history.history['val_loss']\n",
        "acc_val = history.history['loss']\n",
        "epochs = range(1,6)\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.plot(epochs, acc_val, 'g', label='train loss')\n",
        "plt.title('Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JltYGr22Vmp"
      },
      "outputs": [],
      "source": [
        "acc_val = history.history['val_accuracy']\n",
        "acc_train = history.history['accuracy']\n",
        "epochs = range(1,6)\n",
        "plt.plot(epochs, acc_val, 'b', label='validation acc')\n",
        "plt.plot(epochs, acc_train, 'g', label='train_accuracy')\n",
        "plt.title('accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check accuaracy of prediction\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score, recall_score\n",
        "#model.score(x_valid,y_valid)"
      ],
      "metadata": {
        "id": "jQPrL5j2GDx9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cf_matrix=confusion_matrix(y_valid, y_pred)\n",
        "y_test_arg=np.argmax(y_test,axis=1)\n",
        "Y_pred = np.argmax(model.predict(x_test),axis=1) \n",
        "print('Confusion Matrix')\n",
        "cf_matrix=confusion_matrix(y_test_arg, Y_pred)\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Eqt1hEGaN0",
        "outputId": "a4f5b385-5d29-4dfa-ede9-53f346c8f7e5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[5065   31]\n",
            " [  44 4860]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, cmap='coolwarm',annot=True, linewidth=1,fmt=\"d\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "Hlt8eA-DG9Xp",
        "outputId": "9a636ead-829d-4f2c-9353-3bc1ed0d18f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy =accuracy_score(y_test_arg, Y_pred)*100\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60_Clw-Vg3ad",
        "outputId": "e1be01c2-2937-4a3d-a068-74abce20d19d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall = recall_score(y_test_arg, Y_pred , average=\"binary\")\n",
        "precision = precision_score(y_test_arg, Y_pred, average=\"binary\")\n",
        "FPR = cf_matrix[0][1]/(cf_matrix[0][1]+cf_matrix[1][1]) \n"
      ],
      "metadata": {
        "id": "0XhBi_-thCpE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision : \" , precision*100)\n",
        "print(\"Recall : \", recall*100)\n",
        "print(\"Accuracy : \",accuracy)\n",
        "print(\"FPR : \",FPR*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbkk0VGyhlQV",
        "outputId": "1138fdff-af76-4917-b773-fb02e92f0aee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision :  99.36618278470661\n",
            "Recall :  99.10277324632952\n",
            "Accuracy :  99.25\n",
            "FPR :  0.6338172152933961\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN nsl-kdd.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}